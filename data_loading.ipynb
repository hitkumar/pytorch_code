{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_frame = pd.read_csv('faces/face_landmarks.csv')\n",
    "n = 65\n",
    "img_name = landmarks_frame.ix[n, 0]\n",
    "landmarks = landmarks_frame.ix[n, 1:].as_matrix().astype('float')\n",
    "# print (landmarks)\n",
    "landmarks = landmarks.reshape(-1, 2)\n",
    "# print (landmarks)\n",
    "\n",
    "print ('Img name: {}'.format(img_name))\n",
    "print ('Landmarks shape: {}'.format(landmarks.shape))\n",
    "print ('First four landmarks are: {}'.format(landmarks[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_landmarks(image, landmarks):\n",
    "    \"\"\"Show image with landmarks\"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='r')\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "plt.figure()\n",
    "show_landmarks(io.imread(os.path.join('faces/', img_name)),\n",
    "               landmarks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (landmarks_frame.ix[0, 0])\n",
    "68 * 2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FaceLandmarksDataset(Dataset):\n",
    "    '''Face landmarks dataset'''\n",
    "    \n",
    "    def __init__(self, csv_file, root_dir, transformation=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.transformation = transformation\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_name = os.path.join(self.root_dir, landmarks_frame.ix[index, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = landmarks_frame.ix[index, 1:].as_matrix().astype('float')\n",
    "        landmarks = landmarks.reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "        \n",
    "        if self.transformation:\n",
    "            sample = self.transformation(sample)\n",
    "        return sample   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_dataset = FaceLandmarksDataset(csv_file='faces/face_landmarks.csv', \n",
    "                                   root_dir='faces')\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(face_dataset)):\n",
    "    img = face_dataset[i]\n",
    "    print ('Image shape: {}, landmarks shape: {}'.format(img['image'].shape, img['landmarks'].shape))\n",
    "    \n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample: {}'.format(i))\n",
    "    ax.axis('off')\n",
    "    show_landmarks(**img)\n",
    "    \n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "        h, w = image.shape[:2]\n",
    "        # print (\"h is {}, w is {}\".format(h, w))\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "        \n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        image = transform.resize(image, (new_h, new_w))\n",
    "        \n",
    "        landmarks = landmarks * [new_w / w, new_h / h]\n",
    "        return {'image': image, 'landmarks': landmarks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    '''Convert ndarrays into tensors'''\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image), 'landmarks': torch.from_numpy(landmarks)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomCrop(object):\n",
    "    \n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "        \n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "        image = image[top: top + new_h, left: left + new_w]\n",
    "        landmarks = landmarks - [top, left]\n",
    "        \n",
    "        return {'image': image, 'landmarks': landmarks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = Rescale(256)\n",
    "crop = RandomCrop(128)\n",
    "composed = transforms.Compose([Rescale(256), RandomCrop(244)])\n",
    "\n",
    "fig = plt.figure()\n",
    "sample = face_dataset[65]\n",
    "# print (sample)\n",
    "for i, t in enumerate([scale, crop, composed]):\n",
    "    transformed_sample = t(sample)\n",
    "    \n",
    "    ax = plt.subplot(1, 3, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title(type(t).__name__)\n",
    "    show_landmarks(**transformed_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = FaceLandmarksDataset(csv_file='faces/face_landmarks.csv',\n",
    "                                          root_dir='faces',\n",
    "                                          transformation=transforms.Compose([\n",
    "                                              Rescale(256), \n",
    "                                              RandomCrop(244), \n",
    "                                              ToTensor()\n",
    "                                          ]))\n",
    "\n",
    "for i in range(len(transformed_dataset)):\n",
    "    sample = transformed_dataset[i]\n",
    "    print ('type of image: {}, landmark: {}'.format(type(sample['image']), type(sample['landmarks'])))\n",
    "    print ('Image shape: {}, landmarks shape: {}'.format(sample['image'].size(), sample['landmarks'].size()))\n",
    "    \n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(transformed_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "def show_landmarks_batched(sample_batched):\n",
    "    images_batch, landmarks_batch = sample_batched['image'], sample_batched['landmarks']\n",
    "    batch_size = len(images_batch)\n",
    "    im_size = images_batch.size(2)\n",
    "    # print (im_size)\n",
    "    grid = utils.make_grid(images_batch)\n",
    "    # print (grid.shape)\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "    print (landmarks_batch.shape)\n",
    "    for i in range(batch_size):\n",
    "        plt.scatter(landmarks_batch[i, :, 0].numpy() + i * im_size,\n",
    "                   landmarks_batch[i, :, 1].numpy(), \n",
    "                   s = 10, marker='.', c='r')\n",
    "        plt.title('Dataloader batch')\n",
    "\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print (i_batch, sample_batched['image'].size(), sample_batched['landmarks'].size())\n",
    "    if (i_batch == 3):\n",
    "        plt.figure()\n",
    "        show_landmarks_batched(sample_batched)\n",
    "        plt.axis('off')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
